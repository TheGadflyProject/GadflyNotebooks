{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the constant scorekeeping of where tech’s power centers are, two trends stand out in Asia: the continued rise of China as a tech titan and the slow decline of Japan’s once-mighty tech industry.\n",
      "\n",
      "Those currents were evident in two recent developments.\n",
      "\n",
      "On Thursday, Paul Mozur and Jane Perlez reported that American officials had blocked a proposed purchase of a controlling stake in a unit of the Dutch electronics company Philips by Chinese investors because the United States was fearful the deal would be used to further China’s push into microchips.\n",
      "\n",
      "At the center of the concerns was a material called gallium nitride, which was being used by the Philips unit in light-emitting diodes, but which has applications for military and space and can be helpful in semiconductors. The report illustrated how American officials have come to view China’s large and growing tech industry with misgivings.\n",
      "\n",
      "At the same time, Jonathan Soble and Paul Mozur reported that Sharp, one of Japan’s large consumer electronics companies and the biggest LCD producer, was leaning toward a takeover offer from the Taiwanese contract manufacturer Foxconn. The news underlined the decline of Japan’s once-famed consumer electronics companies, which have been undercut in recent years by lower-cost competition from China and South Korea. \n"
     ]
    }
   ],
   "source": [
    "with open(\"../TheGadflyProject/news_articles/China Is Rising.txt\", encoding=\"utf-8\") as f:\n",
    "    source_text = f.read()\n",
    "    \n",
    "print(source_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: 683 In\n",
      "lowercased: 477 in\n",
      "lemma: 477 in\n",
      "shape: 87670 Xx\n",
      "prefix: 467 I\n",
      "suffix: 683 In\n",
      "log probability: -7.603263854980469\n",
      "Brown cluster id: 62\n",
      "----------------------------------------\n",
      "original: 466 the\n",
      "lowercased: 466 the\n",
      "lemma: 466 the\n",
      "shape: 28983 xxx\n",
      "prefix: 3598 t\n",
      "suffix: 466 the\n",
      "log probability: -3.528766632080078\n",
      "Brown cluster id: 11\n",
      "----------------------------------------\n",
      "original: 2839 constant\n",
      "lowercased: 2839 constant\n",
      "lemma: 2839 constant\n",
      "shape: 53740 xxxx\n",
      "prefix: 4206 c\n",
      "suffix: 14180 ant\n",
      "log probability: -10.435121536254883\n",
      "Brown cluster id: 1831\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# all you have to do to parse text is this:\n",
    "#note: the first time you run spaCy in a file it takes a little while to load up its modules\n",
    "parsedData = parser(source_text)\n",
    "\n",
    "# Let's look at the tokens\n",
    "# All you have to do is iterate through the parsedData\n",
    "# Each token is an object with lots of different properties\n",
    "# A property with an underscore at the end returns the string representation\n",
    "# while a property without the underscore returns an index (int) into spaCy's vocabulary\n",
    "# The probability estimate is based on counts from a 3 billion word\n",
    "# corpus, smoothed using the Simple Good-Turing method.\n",
    "for i, token in enumerate(parsedData):\n",
    "    print(\"original:\", token.orth, token.orth_)\n",
    "    print(\"lowercased:\", token.lower, token.lower_)\n",
    "    print(\"lemma:\", token.lemma, token.lemma_)\n",
    "    print(\"shape:\", token.shape, token.shape_)\n",
    "    print(\"prefix:\", token.prefix, token.prefix_)\n",
    "    print(\"suffix:\", token.suffix, token.suffix_)\n",
    "    print(\"log probability:\", token.prob)\n",
    "    print(\"Brown cluster id:\", token.cluster)\n",
    "    print(\"----------------------------------------\")\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "In the constant scorekeeping of where tech’s power centers are, two trends stand out in Asia: the continued rise of China as a tech titan and the slow decline of Japan’s once-mighty tech industry.\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "Those currents were evident in two recent developments.\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "On Thursday, Paul Mozur and Jane Perlez reported that American officials had blocked a proposed purchase of a controlling stake in a unit of the Dutch electronics company Philips by Chinese investors because the United States was fearful the deal would be used to further China’s push into microchips.\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "At the center of the concerns was a material called gallium nitride, which was being used by the Philips unit in light-emitting diodes, but which has applications for military and space and can be helpful in semiconductors.\n",
      "****************************************************************************************************\n",
      "The report illustrated how American officials have come to view China’s large and growing tech industry with misgivings.\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "At the same time, Jonathan Soble and Paul Mozur reported that Sharp, one of Japan’s large consumer electronics companies and the biggest LCD producer, was leaning toward a takeover offer from the Taiwanese contract manufacturer Foxconn.\n",
      "****************************************************************************************************\n",
      "The news underlined the decline of Japan’s once-famed consumer electronics companies, which have been undercut in recent years by lower-cost competition from China and South Korea.\n"
     ]
    }
   ],
   "source": [
    "for sent in parsedData.sents:\n",
    "    print(\"*\" * 100)\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Jane Perlez ', 'China ', 'Chinese ', 'Jonathan Soble ', 'Dutch ', 'Philips ', 'the United States ', 'Foxconn', 'Asia', 'Japan', 'Taiwanese ', 'South Korea', 'Sharp', 'China', 'American ', 'Paul Mozur '}\n"
     ]
    }
   ],
   "source": [
    "entities = set()\n",
    "for ent in parsedData.ents:\n",
    "    if (ent.label_ != \"\") and (ent.label_ not in [\"DATE\", \"TIME\", \"PERCENT\", \"CARDINAL\"]):\n",
    "#         print(ent, ent.label, ent.label_, ent.start)\n",
    "        entities.add(ent.text_with_ws)\n",
    "#         print(parsedData[:ent.start], \"________\", parsedData[ent.end:])\n",
    "print(entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In the constant scorekeeping of where tech’s power centers are, two trends stand out in Asia: the continued rise of China as a tech titan and the slow decline of Japan’s once-mighty tech industry.\n",
      "\n",
      "two  CARDINAL\n",
      "text_with_ws two \n",
      "\n",
      "Asia LOC\n",
      "text_with_ws Asia\n",
      "\n",
      "China  GPE\n",
      "text_with_ws China \n",
      "\n",
      "Japan GPE\n",
      "text_with_ws Japan\n",
      "\n",
      "\n",
      "Those currents were evident in two recent developments.\n",
      "\n",
      "two  CARDINAL\n",
      "text_with_ws two \n",
      "\n",
      "\n",
      "On Thursday, Paul Mozur and Jane Perlez reported that American officials had blocked a proposed purchase of a controlling stake in a unit of the Dutch electronics company Philips by Chinese investors because the United States was fearful the deal would be used to further China’s push into microchips.\n",
      "\n",
      "Thursday DATE\n",
      "text_with_ws Thursday\n",
      "\n",
      "Paul  PERSON\n",
      "text_with_ws Paul \n",
      "\n",
      "Mozur  PERSON\n",
      "text_with_ws Mozur \n",
      "\n",
      "Jane  PERSON\n",
      "text_with_ws Jane \n",
      "\n",
      "Perlez  PERSON\n",
      "text_with_ws Perlez \n",
      "\n",
      "American  NORP\n",
      "text_with_ws American \n",
      "\n",
      "Dutch  NORP\n",
      "text_with_ws Dutch \n",
      "\n",
      "Philips  ORG\n",
      "text_with_ws Philips \n",
      "\n",
      "Chinese  NORP\n",
      "text_with_ws Chinese \n",
      "\n",
      "the  GPE\n",
      "text_with_ws the \n",
      "\n",
      "United  GPE\n",
      "text_with_ws United \n",
      "\n",
      "States  GPE\n",
      "text_with_ws States \n",
      "\n",
      "China GPE\n",
      "text_with_ws China\n",
      "\n",
      "\n",
      "At the center of the concerns was a material called gallium nitride, which was being used by the Philips unit in light-emitting diodes, but which has applications for military and space and can be helpful in semiconductors.\n",
      "\n",
      "Philips  ORG\n",
      "text_with_ws Philips \n",
      "\n",
      "\n",
      "The report illustrated how American officials have come to view China’s large and growing tech industry with misgivings.\n",
      "\n",
      "American  NORP\n",
      "text_with_ws American \n",
      "\n",
      "China GPE\n",
      "text_with_ws China\n",
      "\n",
      "\n",
      "At the same time, Jonathan Soble and Paul Mozur reported that Sharp, one of Japan’s large consumer electronics companies and the biggest LCD producer, was leaning toward a takeover offer from the Taiwanese contract manufacturer Foxconn.\n",
      "\n",
      "Jonathan  PERSON\n",
      "text_with_ws Jonathan \n",
      "\n",
      "Soble  PERSON\n",
      "text_with_ws Soble \n",
      "\n",
      "Paul  PERSON\n",
      "text_with_ws Paul \n",
      "\n",
      "Mozur  PERSON\n",
      "text_with_ws Mozur \n",
      "\n",
      "Sharp ORG\n",
      "text_with_ws Sharp\n",
      "\n",
      "one  CARDINAL\n",
      "text_with_ws one \n",
      "\n",
      "Japan GPE\n",
      "text_with_ws Japan\n",
      "\n",
      "Taiwanese  NORP\n",
      "text_with_ws Taiwanese \n",
      "\n",
      "Foxconn LANGUAGE\n",
      "text_with_ws Foxconn\n",
      "\n",
      "\n",
      "The news underlined the decline of Japan’s once-famed consumer electronics companies, which have been undercut in recent years by lower-cost competition from China and South Korea.\n",
      "\n",
      "Japan GPE\n",
      "text_with_ws Japan\n",
      "\n",
      "recent  DATE\n",
      "text_with_ws recent \n",
      "\n",
      "years  DATE\n",
      "text_with_ws years \n",
      "\n",
      "China  GPE\n",
      "text_with_ws China \n",
      "\n",
      "South  GPE\n",
      "text_with_ws South \n",
      "\n",
      "Korea GPE\n",
      "text_with_ws Korea\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the sentences\n",
    "sents = []\n",
    "# the \"sents\" property returns spans\n",
    "# spans have indices into the original string\n",
    "# where each index value represents a token\n",
    "for span in parsedData.sents:\n",
    "    sent = [parsedData[i] for i in range(span.start, span.end)]\n",
    "    print()\n",
    "    print()\n",
    "    print(''.join(parsedData[i].string for i in range(span.start, span.end)).strip())\n",
    "    for token in sent:\n",
    "        if token.ent_type_ != \"\": \n",
    "            print()\n",
    "            print(token, token.ent_type_)\n",
    "            print(\"text_with_ws\", token.text_with_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gadfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "_parsed_text = parsedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_named_entities():\n",
    "    entities = set()\n",
    "    for ent in _parsed_text.ents:\n",
    "        if (ent.label_ != \"\") and \\\n",
    "            (ent.label_ not in [\"DATE\", \"TIME\", \"PERCENT\", \"CARDINAL\"]):\n",
    "            entities.add(ent.text_with_ws)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _replaceNth(sent, old, new, n):\n",
    "    \"\"\"Replaces the old with new at the nth index in sent\n",
    "    Cite:inspectorG4dget http://stackoverflow.com/a/27589436\"\"\"\n",
    "    inds = [i for i in range(len(sent) - len(old)+1)\n",
    "            if sent[i:i+len(old)] == old]\n",
    "    if len(inds) < n:\n",
    "        return  # or maybe raise an error\n",
    "    # can't assign to string slices. So, let's listify\n",
    "    sent_list = list(sent)\n",
    "    # do n-1 because we start from the first occurrence of the string,\n",
    "    # not the 0-th\n",
    "    sent_list[inds[n-1]:inds[n-1]+len(old)] = new\n",
    "    return ''.join(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Japan :  In the constant scorekeeping of where tech’s power centers are, two trends stand out in Asia: the continued rise of China as a tech titan and the slow decline of _____’s once-mighty tech industry.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "China :  In the constant scorekeeping of where tech’s power centers are, two trends stand out in Asia: the continued rise of _____ as a tech titan and the slow decline of Japan’s once-mighty tech industry.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Asia :  In the constant scorekeeping of where tech’s power centers are, two trends stand out in _____: the continued rise of China as a tech titan and the slow decline of Japan’s once-mighty tech industry.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "China  :  In the constant scorekeeping of where tech’s power centers are, two trends stand out in Asia: the continued rise of _____as a tech titan and the slow decline of Japan’s once-mighty tech industry.\n"
     ]
    }
   ],
   "source": [
    "question_set = set()\n",
    "entities = find_named_entities()\n",
    "for sent in _parsed_text.sents:\n",
    "    for entity in entities:\n",
    "        sent_ents = re.findall(entity, sent.orth_)\n",
    "        if sent_ents:\n",
    "            print(\"-----------\" * 10)\n",
    "            for n in range(len(sent_ents)):\n",
    "                gap_fill_question = _replaceNth(sent.orth_,\n",
    "                                                     entity,\n",
    "                                                     \"_____\",\n",
    "                                                     n\n",
    "                                                     )\n",
    "                print(entity, \": \", gap_fill_question)\n",
    "#                 break\n",
    "#         break\n",
    "    break\n",
    "    #             question = Question(sent.text,\n",
    "    #                                 gap_fill_question,\n",
    "    #                                 entity,\n",
    "    #                                 self.GAP_FILL,\n",
    "    #                                 )\n",
    "    #             question_set.add(question)\n",
    "    # return question_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
